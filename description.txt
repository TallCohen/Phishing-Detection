	פרויקט: גילוי אתרי Phishing בעולם האמיתי:
	(הסבר על הקוד הוספנו בהערות בתוך הקוד ולכן נפרט כאן באופן כללי יותר על התהליך)

	בפרוייקט שלנו יצרנו WEB, אליו מכניסים URL.
	לאחר הכנסת הURL, האתר יחזיר לנו האם הקישור שהכנסנו הוא אתר תקין או חשד לפישינג.

	הקוד שכתבנו מבוסס על שיטה של RULE BASED (מבוססת כללים), שהיא גישה בה אנו מיישמים סדרת כללים שנקבעו מראש כדי לקבל את ההחלטה האם האתר הוא אתר פישינג או לא.
	
	תחילה מוצג דף אליו הגולש נכנס כדי להכניס את כתובת הURL החשודה.
	
	לאחר מכן ננסה לקבל כמה שיותר מידע על הURL החשוד בעזרת ספריות כמו REQUESTS כדי לקבל את תוכן האתר, או BEAUTIFULSOUP כדי לנתח את דף האתר החשוד וכו'
	
	במידה ובשלב זה לא הצלחנו לאתר את הURL נחזיר הודעת שגיאה.
	
	לאחר מכן נשתמש בחוקים שכתבנו מראש, וננסה לראות על כמה חוקים הקישור החשוד עונה. במידה וענה על יותר מ-2 חוקים, מבחינתנו יש חשד שהאתר אינו תקין ויש חשד גדול שהינו אתר פישינג
	
	אם לא ענה על יותר מ-2 חוקים, כנראה שהאתר תקין.
	
	בחרנו לפסול החל מ-2 חוקים ומעלה כיוון שתמיד יש יוצאי דופן, ויתכן שאתר כמו פייסבוק ישתמש בתווים מיוחדים בתוך האתר אבל זה לא אמור לפסול אותו על היותו אתר לא תקין. (כמובן שזה נתון לשינוי ולשיקול מחדש בהתאם להתקדמות הפישינג בעולמנו)
	
	
	במהלך הפרוייקט נתקלנו בקשיים:
	1. כאשר כתבנו חוקים שונים, אתרים תקינים נפסלנו לנו גם, והיינו צריכות לדייק את החוקים בצורה יותר טובה, ולהבין מתי ברצוננו לפסול אתר על היותו חשוד לפישינג ומתי לא. מה שדרש מאיתנו לבצע מחקר מקיף ומעמיק על דפוסי הפישינג הנפוצים כיום.
	2. השתמשנו בCTK על מנת לפתוח חלון של הכנסת הURL ונתקלנו בקשיים עם השימוש בספריה זו, ולכן החלטנו שברצוננו לבצע זאת בעזרת שרת WEB.
	
	